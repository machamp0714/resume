---
layout: doc
---

## 基本情報

|key|value|
|---|---|
| 氏名 | 大出 達也 |
| 生年月日 | 1991/07/14 |
| github | [@machamp0714](https://github.com/machamp0714) |
| Zenn | [@machamp](https://zenn.dev/machamp) |

## スキル

<div class="mb-10">

[![Language](https://skillicons.dev/icons?i=ruby,typescript,javascript,terraform,rails,react,aws,docker&perline=4)](https://skillicons.dev)

</div>

## 職務経歴詳細

### ラフノート株式会社（2020/05〜現在）

:::details **TimeCrowdのバッチシステムのインフラの改善**
### プロジェクト概要

TimeCrowdのバッチシステムは、これまでAWSアカウントの運用を外部の企業に運用を委託していた。
そこで、バッチシステムを自社で管理する AWS アカウントへ移行することとなり、私は AWS アカウントの移行作業全般と、移行先となる新アカウント上でのインフラの設計・構築を担当。

### 基本情報

| 規模  | 3名(自社3名)    |
| --- | ----------- |
| 役割  | メンバー        |
| 担当  | • インフラ設計・構築 |
 
#### 主な機能・業務
- AWS アカウントの移行
- AWS Organizations & IdentityCenter の導入
- IaC の導入
- ECS Fargate・EventBridge Scheduler を利用したバッチ実行基盤の構築
- Datadog を使用したバッチの監視体制の構築
- リザーブドインスタンス・Savings Plan の購入

### 課題
- スタンドアロンなアカウントがサービスごとに存在し、IAM ユーザーも各アカウントに存在するなど、IAM リソースが重複して適切に管理されていなかった。
- EC2にグローバルIPが紐づけられ、アタックサーフェスが広い、S3 にアクセスポリシーが設定されていない、RDS などのリソースが暗号化されていないなど、セキュリティに課題があった。
- 一台のインスタンスで複数のバッチがcronで稼働しており、今後顧客が増えた場合にスケールしにくいという課題があった

#### 成果
- AWS Organizations を導入し、スタンドアロンなアカウントを組織下にまとめました。また IdentityCenter を導入し、Google Workspace と連携することで、各アカウントで IAM ユーザーが重複している問題を解消しました。
- Fargate で1バッチ1コンテナで実行できるようにして、1つのバッチのパフォーマンスの悪化が他のバッチにも影響してしまう問題を解消しました。また、独立した環境でバッチを実行できるため、サーバーの台数を増やすことなくビジネスの成長に対応できるようになりました。
- セキュリティ上の課題に対しては下記の施策を実施しました。
	- Internet Gateway にルーティングされていたのを、NAT Gateway にルーティングするようにネットワークの設計から見直しました。また VPC エンドポイントを追加し、AWS サービスとの通信に関してはプライベートなネットワーク内で完結するように構成しました
	- S3, ECR, SNS などアクセスポリシーを設定する必要があるリソースに関しては最小権限のポリシーを適用しました。
	- RDS、Elasticache のようなサービスは KMS を利用してデータの暗号化を実施しました。

#### 工夫した点
- `tfstate` を環境ごとに分割するのではなく、ライフサイクルが同じという観点でコンポーネント単位(network,storage)で分割しました。環境ごとに分割すると、コードの可読性が悪くなる、CIの実行時間が長くなるという課題がありましたが、コンポーネント単位で分割しました。ただし、この方法では依存関係に注意してデプロイする必要がありますが、 `terragrunt` を採用し、依存関係を管理することで対応しました。
- Datadog のアラートメッセージ中に、runbook を記載した上で Slack にアラートを通知する体制を作りました。runbook にはバッチを再実行する `aws cli` のコマンドを記述し、AWS の知見がない開発メンバーも AWS Chatbot で Slack から aws cli を実行できるようにしました。
- 開発メンバーが AWS 上で作業することなく、スケジュールをデプロイできる体制を作りました。スケジュールは yaml で記述し、それを EventBridge Scheduler 用の module に渡すことで、GitHub Actions でスケジュールを自動でデプロイできるようにしました。
:::

:::details **研修予約システムの開発・運用**
### プロジェクト概要

化粧品・医薬品メーカーが利用する研修予約システムの開発・運用に、開発リーダーとして参画しました。
営業担当が予約の申請を行い、上長が承認、研修担当者が予約を確定するという承認フローがあり、最終的に研修担当者がフィードバックを営業担当に実施するシステム。顧客折衝、要件定義、技術選定、開発、インフラの構築を担当。

### 基本情報

| 規模  | 3名(自社1名,業務委託2名)                    |
| --- | ---------------------------------- |
| 役割  | 開発リーダー                             |
| 担当  | • 設計・コーディング<br>• インフラ構築<br>• 保守・運用 |


### 主な機能・業務

- 月・週表示の切り替え、予約情報の確認、研修の空き状況表示が可能なカレンダーの実装
- `AASM` を利用した承認フローの実装
- 研修の修了証を PDF で発行する機能
- 日本語・英語の2言語に対応した多言語化対応（i18next を使用）
- Fargate を利用したコンテナ基盤の構築

### 課題

- 「顧客管理のマスタに Salesforce を使用したい」というご要望をプロジェクトの初期段階で頂いていたが、Salesforce の設計が完了しておらず、また完了時期も未定でお見積もりを作成できない状況だった。
- 予約の承認状態は、「仮予約申請中」、「上長承認済み」、「却下」など、合計10種類の状態が存在しました。さらに、「管理者」、「一般ユーザー」といったユーザー権限に応じて、それぞれ操作できる項目（予約の日程など）が異なるため、UIの全容を把握することが困難だった。

### 成果
- 第一フェーズでは DB に顧客情報を持たせ、第二フェーズで Salesforce と連携する方針を提案しご承諾頂きました。開発方針としては、API をフェーズごとにバージョンを分けて開発し、段階的に移行できる体制を作りました。
- チーム開発におけるコード品質と保守性の向上を目的とし、bullet proof react のアーキテクチャパターンを採用し、コーディング規約をドキュメント化することで、メンバー間で認識を統一しました。`features/featureA` は `features/featureB` に依存してはいけないなど、特定フォルダからの `import` を禁止することで、依存関係が複雑化することを回避し、他の開発メンバーが実装されている場所を見つけやすい設計を実現しました。

### 工夫した点

- OpenAPI によるスキーマ駆動開発を導入し、`openapi-typescript` を利用して、定義したスキーマから TypeScript の型を自動生成しました。これにより、フロントエンドとバックエンドの開発を並行して進めることができ、作業の振り分けがスムーズになりました。また、API の仕様と型定義のずれが発生することを防ぐことができました。
- Storybook を採用し、全ての承認状態（10種類）の Story を定義することで、開発者は各々テストデータを用意することなく各状態の UI を確認できる体制を整えました。また、Storybook の Decorator と ArgTypes を利用して、ユーザー権限を切り替える仕組みを実装しました。これにより、実際にログインユーザーを切り替えることなく、動作検証する体制を作ることで、UI のテストに掛かる時間を削減することができました

#### 技術選定について

プロジェクト初期の要件定義の段階で、下記の課題が存在し、フロントエンドの開発の重要性が高いと判断しました。

1. 月・週表示を持つカレンダーやモーダル内フォームなど、インタラクションが豊富で複雑なUIの実装が求められており、jQuery や Stimulus では、これらの UI を品質と保守性を維持しながら実装するのは困難だと判断した
2. フォームで扱うデータ構造が、配列内に配列が含まれるなど複雑だった
3. 10種類にも及ぶ承認状態に応じてUIが変化するため、UIテストに多大な工数がかかることが予想された

これらの課題を考慮し、React の導入を検討し始め、他社の採用実績や、React の開発経験がある先輩のエンジニアがいる考慮して、React が最適であると判断しました。
TypeScript も併せて使用することで型安全性の恩恵を受けつつ、React の宣言的 UI の特性により複雑な UI をコンポーネント単位で管理することで、コードの見通しが良くなり保守性が向上できると考えました。
また、フォームの実装に関しては、 `react-hook-form` などのライブラリを活用することで、ネストされた配列などの構造が扱いやすくなると見込みました。さらに Storybook を利用し、承認状態ごとに UI を確認・テストできる環境を用意することで、テストに掛かる時間を削減できると考えました。
導入コストに関しては、フロントエンドとバックエンドを完全に分けるのではなく、mastdon のリポジトリを参考にしたモノレポ構成にすることで、Rails の資産（認証、ルーティング）を活かしつつ、React は部分的に適用することで導入コストが下げられると考えました。また、 状態管理については、Redux, Recoil, Zustand など多数の選択肢がある中で、本プロジェクトでは管理したいグローバルな状態がユーザーの認証情報と、Feature Flag の値と少ないかつ、今後も増えることもあまり無い判断し、`React Context` を採用することで学習コストを下げられると考えました。
:::

:::details **助成金支援サービスの開発・運用**

### プロジェクト概要

中小企業向けに、補助金申請のプロセスを効率化し、採択率向上を支援するSaaS型経営支援サービスの開発・運用に開発メンバーとして参画。運営者が作成した補助金申請の解説動画を視聴したり、コンサルタントとメッセージのやり取りをしながら経営者の助成金申請の書類作成をサポートする。
会員向け機能（動画視聴、コンサルタント予約、メッセージ機能等）および、一部管理者向け機能の開発を担当。

### 基本情報

| 規模  | 3名(自社2名,業務委託1名)           |
| --- | ------------------------- |
| 役割  | メンバー                      |
| 担当  | コーディング<br>インフラ構築<br>保守・運用 |

### 主な機能・業務

- Sendgrid を利用したメール送信機能
- コンサルの予約機能
- メッセージ機能
- 運用コストを考慮して選定した ECS を利用したコンテナ基盤の構築
- セキュリティ強化のため、AWS Workspace を活用した管理画面へのアクセス制限（特定のIPアドレスからのアクセスのみ許可）
- 外部からの攻撃対策として WAF の設定
- Fluent Bit を利用したログ基盤構築
- インフラ変更の迅速化と属人化防止を目的とした IaC の導入

### 課題

- 高いセキュリティ基準を求められ、特に管理画面へのアクセス制御とログ管理において厳格な対応が必要だった。
    - フルリモートの、会社だが管理画面へのアクセスにはオフィス内に専用のエリアを用意して、専用の端末からのみアクセスできるようにする、という物理的な制限を設ける必要があった
	- 機微情報を含むログとそれ以外のログで保管期間が異なるため、ログの出力先を分ける必要があった（機微情報を含むログは7年間、それ以外は3ヶ月）
	- アクセス制御ポリシーの追加・変更の手順は全て文書化し、監査することが求められた
- 業務上、初めて ECS を利用してコンテナ基盤を構築する必要があり、本番用の Dockerfile の作成、タスク定義・サービス定義の適切な設定方法をキャッチアップする必要があった。

### 成果

- AWS Workspaces を経由したアクセスのみを許可する構成を構築し、管理画面への不正アクセスリスクを最小限に抑えることができました。
- Fluent Bit を活用し、ログ内の項目（例：ユーザーID、操作内容など）に応じてログを出力するログストリームを分け、機微情報を含むログストリーム内のログを S3 にエクスポートする Lambda Function を月初に実行する仕組みを構築した。これにより、ロググループのログの保存期間を3ヶ月に設定することができ、CloudWatch Insights の検索時間を短縮することもできました。
- Terraform を用いた IaC を導入することで、インフラもアプリケーション同様、GitHub フローに則り変更を実施することで、多くの開発者に馴染んだ手順を作成しました。またバックエンドには Terraform Cloud を採用することで、インフラ変更の監査ログを蓄積することもできました。
- 技術検証用のアカウントを作成し、ECS をまず手動で作成し、コンテナが正常に稼働するために必要な要素（タスク定義、サービス定義、ネットワーク設定など）をキャッチアップ。その後、GitHub Actions と ecspresso でデプロイを自動化し、継続的デリバリーの基盤を構築しました。この経験を通じ、他の EC2 で稼働しているプロジェクトも OS の管理を AWS に委任するため Fargate に移行するなど、本件の経験を活かせることができました。

### 工夫した点

- lograge gemを使用して、Rails のログを json 構造に変換することで、CloudWatch Logs Insights を利用してログを検索しやすくした。また、 `Rails.logger.info` を利用した場合は lograge を使用しても json 構造に変換されないという問題があったため、ログフォーマッターを独自に実装しました。
:::

:::details **社内ポータルサイトのリニューアル・運用**

### プロジェクト概要

社内報システムのリプレイス

社内報システムのリプレイスプロジェクトに、プロジェクトリーダー兼開発エンジニアとして参画しました。データベース設計の問題、サーバーの外部公開、HTTP 通信の使用などセキュリティ上の課題があったため、セキュリティ強化とUXの改善、新機能の追加を目的とし、Ruby on Rails と Box を活用した新システムへの移行を実施。私は、入社1ヶ月目から本プロジェクトにアサインされ、顧客折衝から要件定義、設計、開発、テスト、リリースまでの一連の工程をリードしました。

### 主な機能・業務

- セキュリティ強化とユーザー管理の効率化を目的とした Okta 認証基盤の導入
- TinyMCE を活用した WYSIWYG エディタの実装と、記事内画像の Box 自動アップロード機能の開発
- 記事公開時に、記事タイトルと本文を Slack の指定チャンネルに自動通知する機能の実装
- ユーザー情報の CSV エクスポート機能の開発
- Ruby/Rails の最新バージョンへのアップグレード対応

### 基本情報

| 規模  | 2名(自社1名,業務委託1名) |
| --- | --------------- |
| 役割  | 開発リーダー          |
| 担当  | • 設計・コーディング<br>• インフラの移行<br>• 保守・運用     |

### 課題

- 入社1ヶ月で、顧客折衝から開発まで案件全体を担当することになり、既存システムの仕様把握、顧客との要件調整、技術的なキャッチアップを同時に行う必要があった
- データベースの正規化が不適切（ユーザーテーブルに部署名が含まれているなど）で、カラムの命名が分かりににくいなど、データベースの設計に問題があった
- ファイル共有の効率化のため、サーバー上に保存されていた数千件の静的ファイル（画像、PDFなど）を全て Box へ移行する必要があった
- HTTPが使用されていたため、通信の盗聴・改竄防止のためHTTPS による通信を実現する必要があった

### 成果

- 本番データや外部サービスとの連携が不要な開発タスク（例：一部の画面のフロントエンド改修）を、業務委託のエンジニアにアサインしました。お互いにソースコードレビューを実施することで、品質を担保しながら、私自身はコア機能の開発と顧客対応に集中することができ、結果として、スケジュール通りリプレイスを完遂しました。
- 新しいテーブル設計に対応した Rake タスクを開発し、既存データの完全な移行を実現しました。具体的には、部署テーブルと社員テーブルを適切に分割し、部署コードを外部キーとして社員テーブルから参照する形に正規化しました。
- 静的ファイルを新サーバーへ SCP で転送し、 Box へアップロードする Rake タスクを実行することで、全ファイルの移行を完遂しました。
- EC2 上に Rails 環境を構築し、ALB と ACM を活用し、HTTPS 通信を実現しました。

### 工夫した点

- CircleCI で CI/CD パイプラインを構築し、単体テスト(RSpec)と結合テストの自動化、および Capistrano による本番環境への自動デプロイを実現しました。これにより、開発効率の向上と人為的ミスの削減を実現しました。
- 記事内の画像をBox へ移行する際、正規表現による抽出ではなく、Nokogiri を使用した HTML パース処理を採用することで、より堅牢な実装を実現しました。
- コスト最適化のため、1台の EC2 インスタンス上で Nginx によるバーチャルホストの設定を行い、ホスト名に応じてバックエンドのアプリケーションサーバー（puma）へ振り分ける構成にしました。
:::

## 業務外活動

| タイトル | 説明 | github | URL |
| --- | --- | --- | --- |
| timecrowd-tracker | Raycast Extension | https://github.com/machamp0714/timecrowd-tracker | https://www.raycast.com/machamp0714/timecrowd-tracker |
